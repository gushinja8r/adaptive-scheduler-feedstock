{% set name = "adaptive-scheduler" %}
{% set version = "0.2.3" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/adaptive_scheduler-{{ version }}.tar.gz
  sha256: 02be623e5d6ff7d2629db38b30e434d1504e4b0f509cb06ce6007ba99973879d

build:
  number: 0
  skip: True  # [win]
  skip: True  # [py<37]
  script: "{{ PYTHON }} -m pip install . --no-deps -vv"

requirements:
  host:
    - python
    - pip
  run:
    - python
    - adaptive
    - dill
    - mpi4py
    - pyzmq
    - structlog
    - tinydb
    - toolz
    - tqdm

test:
  imports:
    - adaptive_scheduler

about:
  home: http://github.com/basnijholt/adaptive-scheduler
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: 'An asynchronous scheduler using MPI for Adaptive'
  description: |
    The Adaptive scheduler solves the following problem, you
    need to run a few 100 learners and can use >1k cores. You
    can't use a centrally managed place that is responsible
    for all the workers (like with dask or ipyparallel)
    because >1k cores is too many for them to handle. You
    also don't want to use dask or ipyparallel inside a job
    script because they write job scripts on their own.
    Having a job script that runs code that creates job
    scripts...
    With adaptive-scheduler you only need to define the
    learners and then it takes care of the running
    (and restarting) of the jobs on the cluster.

  doc_url: https://github.com/basnijholt/adaptive-scheduler
  dev_url: https://github.com/basnijholt/adaptive-scheduler

extra:
  recipe-maintainers:
    - basnijholt
