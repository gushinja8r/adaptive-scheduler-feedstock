{% set name = "adaptive-scheduler" %}
{% set version = "0.2.7" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/adaptive_scheduler-{{ version }}.tar.gz
  sha256: 6192e2e26d687e901e1006d4fccff515578633e8e8b642388a9c9975c08e2db3

build:
  number: 0
  skip: True  # [win]
  skip: True  # [py<37]
  script: "{{ PYTHON }} -m pip install . --no-deps -vv"

requirements:
  host:
    - python
    - pip
  run:
    - python
    - adaptive
    - dill
    - ipyparallel
    - mpi4py
    - psutil
    - pyzmq
    - structlog
    - tinydb
    - toolz
    - tqdm

test:
  imports:
    - adaptive_scheduler

about:
  home: http://github.com/basnijholt/adaptive-scheduler
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  summary: 'An asynchronous scheduler for Adaptive'
  description: |
    The Adaptive scheduler solves the following problem, you need to run a few 100 
    learners and can use >1k cores. `ipyparallel` and `dask.distributed` provide 
    very powerful engines for interactive sessions. However, when you want to 
    connect to >1k cores it starts to struggle. Besides that, on a shared cluster 
    there is often the problem of starting an interactive session with ample space 
    available. Our approach is to schedule a different job for each `
    adaptive.Learner`. The creation and running of these jobs are managed by `
    adaptive-scheduler`. This means that your calculation will definitely run, even 
    though the cluster might be fully occupied at the moment. Because of this 
    approach, there is almost no limit to how many cores you want to use. You can 
    either use 10 nodes for 1 job (`learner`) or 1 core for 1 job (`learner`) while 
    scheduling hundreds of jobs. Everything is written such that the computation is 
    maximally local. This means that is one of the jobs crashes, there is no 
    problem and it will automatically schedule a new one and continue the 
    calculation where it left off (because of Adaptive's periodic saving 
    functionality). Even if the central "job manager" dies, the jobs will continue 
    to run (although no new jobs will be scheduled.) 
  doc_url: http://adaptive-scheduler.readthedocs.io
  dev_url: https://github.com/basnijholt/adaptive-scheduler

extra:
  recipe-maintainers:
    - basnijholt
